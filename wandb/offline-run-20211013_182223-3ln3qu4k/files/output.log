10/13/2021 18:22:29 - WARNING - __main__ -   Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False
10/13/2021 18:22:30 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to C:\Users\Marco\AppData\Local\Temp\tmpuj_nv14n
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 433/433 [00:00<00:00, 72134.63B/s]
10/13/2021 18:22:30 - INFO - pytorch_transformers.file_utils -   copying C:\Users\Marco\AppData\Local\Temp\tmpuj_nv14n to cache at C:\Users\Marco\.cache\torch\pytorch_transformers\4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
10/13/2021 18:22:30 - INFO - pytorch_transformers.file_utils -   creating metadata file for C:\Users\Marco\.cache\torch\pytorch_transformers\4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
10/13/2021 18:22:30 - INFO - pytorch_transformers.file_utils -   removing temp file C:\Users\Marco\AppData\Local\Temp\tmpuj_nv14n
10/13/2021 18:22:30 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at C:\Users\Marco\.cache\torch\pytorch_transformers\4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
10/13/2021 18:22:31 - INFO - pytorch_transformers.modeling_utils -   Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "factcc_annotated",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pad_token_id": 0,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}
10/13/2021 18:22:31 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to C:\Users\Marco\AppData\Local\Temp\tmpyfgloiph
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 231508/231508 [00:00<00:00, 399688.05B/s]
10/13/2021 18:22:33 - INFO - pytorch_transformers.file_utils -   copying C:\Users\Marco\AppData\Local\Temp\tmpyfgloiph to cache at C:\Users\Marco\.cache\torch\pytorch_transformers\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
10/13/2021 18:22:33 - INFO - pytorch_transformers.file_utils -   creating metadata file for C:\Users\Marco\.cache\torch\pytorch_transformers\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
10/13/2021 18:22:33 - INFO - pytorch_transformers.file_utils -   removing temp file C:\Users\Marco\AppData\Local\Temp\tmpyfgloiph
10/13/2021 18:22:33 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\Marco\.cache\torch\pytorch_transformers\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
10/13/2021 18:22:33 - INFO - __main__ -   Loading model from checkpoint.
10/13/2021 18:22:34 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to C:\Users\Marco\AppData\Local\Temp\tmp_wfs3a6h
100%|████████████████████████████████████████████████████████████████████████████████████████████████| 440473133/440473133 [28:06<00:00, 261172.01B/s]
10/13/2021 18:50:41 - INFO - pytorch_transformers.file_utils -   copying C:\Users\Marco\AppData\Local\Temp\tmp_wfs3a6h to cache at C:\Users\Marco\.cache\torch\pytorch_transformers\aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
10/13/2021 18:50:42 - INFO - pytorch_transformers.file_utils -   creating metadata file for C:\Users\Marco\.cache\torch\pytorch_transformers\aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
10/13/2021 18:50:42 - INFO - pytorch_transformers.file_utils -   removing temp file C:\Users\Marco\AppData\Local\Temp\tmp_wfs3a6h
10/13/2021 18:50:42 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at C:\Users\Marco\.cache\torch\pytorch_transformers\aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
10/13/2021 18:50:47 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
10/13/2021 18:50:47 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
10/13/2021 18:50:47 - INFO - __main__ -   Training/evaluation parameters Namespace(data_dir='factCC/', model_type='bert', model_name_or_path='bert-base-uncased', task_name='factcc_annotated', output_dir='factCC/', train_from_scratch=False, config_name='', tokenizer_name='', cache_dir='', max_seq_length=512, do_train=False, do_eval=False, do_predict=True, evaluate_during_training=False, do_lower_case=True, per_gpu_train_batch_size=12, per_gpu_eval_batch_size=8, gradient_accumulation_steps=1, learning_rate=5e-05, loss_lambda=0.1, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_steps=100, save_steps=50, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=False, overwrite_cache=True, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, n_gpu=0, device=device(type='cpu'), output_mode='classification')
10/13/2021 18:50:47 - INFO - __main__ -   Evaluate the following checkpoints: []